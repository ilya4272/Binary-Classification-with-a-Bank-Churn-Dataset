{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Content\n",
    "\n",
    "# 1- Libraries\n",
    "# 2- API Integration\n",
    "# 3- Download the Files\n",
    "# 4- Read the Files\n",
    "\n",
    "# 5- Data Preparation\n",
    "# 5.1 Drop Unnecessary Columns \n",
    "# 5.2 Encoding\n",
    "\n",
    "# 6- Exploratory Data Analysis\n",
    "# 6.1- Statistical Analysis\n",
    "# 6.2- Histograms\n",
    "# 6.3- Distributions\n",
    "# 6.4- Scatter-Plotting\n",
    "# 6.5- Outliers Checking\n",
    "\n",
    "# 7- Building Model-0 // Benchmark\n",
    "\n",
    "# 8- Data Cleaning\n",
    "# 8.1- Drop Outliers\n",
    "# 8.1.1- Balance\n",
    "# 8.1.2- EstimatedSalary\n",
    "# 8.2- Standart Scaler\n",
    "\n",
    "\n",
    "# 9- Handling Imbalanced Data\n",
    "# 10- Building Model-1 // Improvements\n",
    "# 11- Feature Engineering\n",
    "# 12- Hyperparameter Tuning\n",
    "# 13- Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1- Libraries\n",
    "\n",
    "# Data Manipulation and Cleaning Libraries\n",
    "import pandas as pd  # For data manipulation and data frames\n",
    "import numpy as np  # For numerical operations and arrays\n",
    "\n",
    "# File and System Operations Libraries\n",
    "import os  # For operating system interactions, like file handling\n",
    "import sys\n",
    "import zipfile  # For working with zip files\n",
    "\n",
    "# Dataset Access Libraries\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi  # For accessing datasets from Kaggle\n",
    "from config import *  # Importing custom configurations\n",
    "from model_eval_func import evaluate_model_performance, evaluate_model  # Custom model evaluation functions\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import seaborn as sns  # For advanced data visualization\n",
    "from matplotlib import pyplot as plt  # For plotting graphs and charts\n",
    "import matplotlib  # For customizing matplotlib settings\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler  # For converting categorical data to numerical and scaling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold  # Model selection and evaluation\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  # Ensemble methods\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report  # Model evaluation metrics\n",
    "from xgboost import XGBClassifier  # XGBoost classifier\n",
    "from imblearn.over_sampling import RandomOverSampler  # Handling imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "competition = comp\n",
    "api.competition_download_files(competition, path=path_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Download the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file\n",
    "zip_file_path = os.path.join(path_1, 'playground-series-s4e1.zip')  # Burada dosya adını doğru şekilde belirtin\n",
    "\n",
    "# Extract the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path_1)\n",
    "\n",
    "print(f\"Zip Files Saved...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Read the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data klasörünün yolu\n",
    "raw_data_directory = path_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasörün içindeki dosyaları listeleme\n",
    "if os.path.exists(path_1) and os.path.isdir(path_1):\n",
    "    files = os.listdir(path_1)\n",
    "    print(\"Files in the Raw Folder:\")\n",
    "    print(\" \")\n",
    "    for file in files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"Belirtilen klasör yok veya bir dizin değil.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasördeki dosyaları listele\n",
    "files = os.listdir(path_1)\n",
    "\n",
    "print(\"Dataframes: \")\n",
    "print(\"\")\n",
    "\n",
    "# CSV dosyalarını oku ve değişken olarak kaydet\n",
    "for csv_file in files:\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(path_1, csv_file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Dosya adını kullanarak değişken adını belirle\n",
    "        var_name = os.path.splitext(csv_file)[0] + '_df'\n",
    "        \n",
    "        # DataFrame'i globals() fonksiyonunu kullanarak kaydet\n",
    "        globals()[var_name] = df\n",
    "\n",
    "        print(f\"{var_name} saved...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Drop Unnecessary Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_df as main dataset\n",
    "df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Data\n",
    "df_org = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['id','CustomerId','Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset\n",
    "df_2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Encoding 'Geography' column\n",
    "df_2['Geography'] = labelencoder.fit_transform(df_2['Geography'])\n",
    "\n",
    "# Encoding 'Gender' column\n",
    "df_2['Gender'] = labelencoder.fit_transform(df_2['Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6- Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatype and blanks\n",
    "df_2.info()\n",
    "df_2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1- Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Distribution\n",
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CreditScore:\n",
    "The average credit score is 656.45, with scores ranging from 350 to 850. \n",
    "The median score is 659, indicating that half of the observations have a credit score below this value. \n",
    "The standard deviation of 80.10 suggests moderate variability in credit scores among the customers.\n",
    "\n",
    "Geography:\n",
    "The encoded geography values (0, 1, 2) show an average value of 0.65. \n",
    "With a standard deviation of 0.82, this indicates a diverse distribution of customers across different regions. \n",
    "The median value is 0, implying that a significant portion of the data is concentrated in the lowest encoded region.\n",
    "\n",
    "Gender:\n",
    "The average encoded value for gender is 0.56, reflecting a slightly higher proportion of one gender in the dataset. \n",
    "The median value of 1 shows that more than half of the observations are of the higher encoded gender value.\n",
    "\n",
    "Age:\n",
    "The average age of the customers is 38.13 years, with ages ranging from 18 to 92 years. \n",
    "The median age is 37 years, indicating a young to middle-aged customer base. \n",
    "The standard deviation of 8.87 suggests some variability in age distribution.\n",
    "\n",
    "Tenure:\n",
    "Customers have an average tenure of 5.02 years, with a range from 0 to 10 years. \n",
    "The median tenure is 5 years, suggesting that half of the customers have been with the organization for this duration. \n",
    "The standard deviation of 2.81 indicates some variation in tenure.\n",
    "\n",
    "Balance:\n",
    "The average account balance is 55,478.09, with balances ranging from 0 to 250,898.09. \n",
    "The median balance is 117,948.00, showing that half of the customers have a balance below this amount. \n",
    "A high standard deviation of 62,817.66 indicates significant variability in account balances.\n",
    "\n",
    "NumOfProducts:\n",
    "On average, customers have 1.55 products, with a median of 2 products. \n",
    "The range is from 1 to 4 products, and the standard deviation of 0.55 indicates some variation in the number of products held by customers.\n",
    "\n",
    "HasCrCard:\n",
    "The average value for credit card possession is 0.75, indicating that a majority of customers have a credit card. \n",
    "The standard deviation of 0.43 shows a significant portion without credit cards.\n",
    "\n",
    "IsActiveMember:\n",
    "The average value for active membership is 0.50, with a median of 1. \n",
    "This indicates an equal distribution between active and inactive members.\n",
    "\n",
    "EstimatedSalary:\n",
    "The average estimated salary is 112,574.82, with values ranging from 11.58 to 199,992.48. \n",
    "The median salary is 117,948.00, suggesting a moderately high-income customer base. \n",
    "The standard deviation of 50,292.87 indicates a wide range of salaries.\n",
    "'''\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2- Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "df_2.hist(bins=30, figsize=(20, 15))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3- Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_2 is your DataFrame\n",
    "numeric_columns = df_2.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "plt.figure(figsize=(15, 10))  # Adjusting the size to accommodate all subplots\n",
    "\n",
    "for i, column in enumerate(numeric_columns, 1):\n",
    "    plt.subplot(3, 4, i)  # Adjust the number of rows and columns if necessary\n",
    "    sns.histplot(df_2[column], kde=True)\n",
    "    plt.title(column)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4- Scatter-Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between columns\n",
    "plt.figure(figsize=(8, 3))  # Grafik boyutunu küçülttük\n",
    "plt.scatter(df_2['EstimatedSalary'], df_2['Balance'], label='Data Points')\n",
    "plt.xlabel('EstimatedSalary')\n",
    "plt.ylabel('Balance')\n",
    "plt.title('Relationship between Estimated Salary and Balance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5- Outliers Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot the Boxplot\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "sns.boxplot(data=df_2)\n",
    "plt.xticks(rotation=45, fontsize=8)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7- Building Model-0 // Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent Features\n",
    "X = df_2[['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'IsActiveMember', 'EstimatedSalary']]\n",
    "\n",
    "# Dependent Features\n",
    "y = df_2['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression modelini oluşturma ve eğitme\n",
    "clf = LogisticRegression(solver=\"liblinear\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Model Evaluation\n",
    "evaluate_model(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model Success Metrics Visuals\n",
    "evaluate_model_performance(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## Evaluation:\n",
    "\n",
    "ROC AUC measures the model's classification ability, and the closer it is to 1, the better the model performs. \n",
    "The ROC AUC score for the training set is 0.714, while the score for the test set is 0.712. \n",
    "These scores indicate that the model's classification ability is reasonable but not perfect.\n",
    "'''\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## Conclusions and Recommendations:\n",
    "\n",
    "Performance Improvement:\n",
    "The model's ROC AUC score is around 0.71, suggesting that there is room for improvement in classification performance. \n",
    "This could be achieved by employing more complex models or by performing feature engineering to enhance the model's accuracy.\n",
    "\n",
    "Balanced Dataset and Other Metrics:\n",
    "If there is class imbalance in the dataset, the accuracy metric might be misleading. \n",
    "In such cases, it is beneficial to consider other metrics such as precision, recall, and F1 score.\n",
    "\n",
    "Overfitting/Underfitting Analysis:\n",
    "The training and test accuracies are quite close, indicating that the model is not overfitting and has a reasonable generalization capability. \n",
    "However, to further improve the model and capture more complex patterns in the data, more advanced models (e.g., Random Forest, Gradient Boosting) \n",
    "can be tried.\n",
    "\n",
    "In conclusion, the current model performs well as a baseline evaluation. \n",
    "However, additional model tuning and data preprocessing steps can be undertaken to enhance performance, \n",
    "particularly to achieve higher accuracy and better ROC AUC scores.\n",
    "'''\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8- Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset\n",
    "df_3 = df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1- Drop Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1.1- Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where Balance is zero\n",
    "df_3 = df_3[df_3['Balance'] != 0]\n",
    "\n",
    "# Calculate Q1 and Q3 on the non-zero Balance values\n",
    "Q1 = df_3['Balance'].quantile(0.10)\n",
    "Q3 = df_3['Balance'].quantile(0.90)\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers among the non-zero balances\n",
    "outliers = (df_3['Balance'] < lower_bound) | (df_3['Balance'] > upper_bound)\n",
    "\n",
    "# Remove the identified outliers\n",
    "df_3 = df_3[~outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))  \n",
    "sns.histplot(df_3['Balance'], bins=50) \n",
    "plt.xlabel('Balance')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Balance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1.2- EstimatedSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where Balance is zero\n",
    "df_3 = df_3[df_3['EstimatedSalary'] > 0]\n",
    "\n",
    "# Calculate Q1 and Q3 on the non-zero Balance values\n",
    "Q1 = df_3['EstimatedSalary'].quantile(0.10)\n",
    "Q3 = df_3['EstimatedSalary'].quantile(0.90)\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers among the non-zero balances\n",
    "outliers = (df_3['EstimatedSalary'] < lower_bound) | (df_3['EstimatedSalary'] > upper_bound)\n",
    "\n",
    "# Remove the identified outliers\n",
    "df_3 = df_3[~outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Histogram for EstimatedSalary\n",
    "plt.figure(figsize=(8, 2))  \n",
    "sns.histplot(df_3['EstimatedSalary'], bins=50) \n",
    "plt.xlabel('EstimatedSalary')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of EstimatedSalary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2- Standart Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset\n",
    "df_4 = df_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to scale\n",
    "columns_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "df_4[columns_to_scale] = min_max_scaler.fit_transform(df_4[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output\n",
    "df_4 = df_4.reset_index(drop=True)\n",
    "\n",
    "df_4.info()\n",
    "df_4.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9- Building Model-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent Features\n",
    "X = df_4[['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'IsActiveMember', 'EstimatedSalary']]\n",
    "\n",
    "# Dependent Features\n",
    "y = df_4['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression Model \n",
    "clf = LogisticRegression(solver=\"liblinear\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Model Evaluation\n",
    "evaluate_model(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model Success Metrics Visuals\n",
    "evaluate_model_performance(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2- Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models initialization\n",
    "log_reg = LogisticRegression(solver=\"liblinear\")\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "log_reg.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating\n",
    "models = {\n",
    "    'Logistic Regression': log_reg,\n",
    "    'Decision Tree': decision_tree,\n",
    "    'Random Forest': random_forest\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the this scores, Random Forest Best Model, deep dive on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Model Evaluation\n",
    "evaluate_model(random_forest, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model Success Metrics Visuals\n",
    "evaluate_model_performance(random_forest, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is so obivous that model is overfitting. That's why Logistic Regression is still the best one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3- Gradient Boosting Machines (GBM) and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "xgboost = XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train models\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating\n",
    "models = {\n",
    "    'Gradient Boosting': gradient_boosting,\n",
    "    'XGBoost': xgboost\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Model Evaluation\n",
    "evaluate_model(gradient_boosting, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model Success Metrics Visuals\n",
    "evaluate_model_performance(gradient_boosting, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Model Evaluation\n",
    "evaluate_model(xgboost, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model Success Metrics Visuals\n",
    "evaluate_model_performance(xgboost, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Model is very good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10- Inblance Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf dağılımını kontrol etme\n",
    "class_distribution = y.value_counts(normalize=True)\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is inbalance dataset that need to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Random over-sampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(df_4.drop(columns='Exited'), df_4['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf dağılımını kontrol etme\n",
    "class_distribution = y_resampled.value_counts(normalize=True)\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression modeli\n",
    "log_reg = LogisticRegression(solver=\"liblinear\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Gradient Boosting modeli\n",
    "gradient_boost = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gradient_boost.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost modeli\n",
    "xgboost = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelleri değerlendirme\n",
    "models = {\n",
    "    'Logistic Regression': log_reg,\n",
    "    'Gradient Boosting': gradient_boost,\n",
    "    'XGBoost': xgboost\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    print(\"\")\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Dive Gradient Boosting and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Model Evaluation\n",
    "evaluate_model(xgboost, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model Success Metrics Visuals\n",
    "evaluate_model_performance(xgboost, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Model Evaluation\n",
    "evaluate_model(gradient_boost, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model Success Metrics Visuals\n",
    "evaluate_model_performance(gradient_boost, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is xgboost.\n",
    "It show high performance for both train and test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11- Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1 Correlation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X_resampled.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "corr_select = sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "bottom, top = corr_select.get_ylim()\n",
    "\n",
    "corr_select.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated columns \n",
    "\n",
    "def correlated_columns(X_resampled, threshold):\n",
    "    \n",
    "    col_corr    = set()\n",
    "    corr_matrix = X_resampled.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "    \n",
    "        for j in range(i):\n",
    "                   \n",
    "            if corr_matrix.iloc[i,j] > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "                   \n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the correlation between columns are higher than 80% then drop these columns\n",
    "\n",
    "corr_features = correlated_columns(X_resampled, 0.9)\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2 Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farklı özellik sayıları için döngü\n",
    "results = []\n",
    "for n_features in range(1, X_train.shape[1] + 1):\n",
    "    rfe = RFE(estimator=xgb_model, n_features_to_select=n_features)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    \n",
    "    # Seçilen özelliklerle modeli eğitme\n",
    "    X_train_rfe = X_train.loc[:, rfe.support_]\n",
    "    X_test_rfe = X_test.loc[:, rfe.support_]\n",
    "    xgb_model.fit(X_train_rfe, y_train)\n",
    "    \n",
    "    # Modeli değerlendirme\n",
    "    y_pred = xgb_model.predict(X_test_rfe)\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test_rfe)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results.append((n_features, accuracy, roc_auc))\n",
    "\n",
    "# Sonuçları yazdırma\n",
    "for n_features, accuracy, roc_auc in results:\n",
    "    print(f\"Number of features: {n_features}, Accuracy: {accuracy:.4f}, ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performance with all feature, no need to drop any features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12- Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter ızgarası\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# XGBoost modeli\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# En iyi parametreler\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best ROC AUC score: {grid_search.best_score_}\")\n",
    "\n",
    "# En iyi model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Model değerlendirme\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Accuracy: {accuracy:.4f}, ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Hyperparameter dağılımı\n",
    "param_dist = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=50, stop=200, num=10)],\n",
    "    'max_depth': [int(x) for x in np.linspace(3, 10, num=8)],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# XGBoost modeli\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=100, cv=3, scoring='roc_auc', n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# En iyi parametreler\n",
    "print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "print(f\"Best ROC AUC score: {random_search.best_score_}\")\n",
    "\n",
    "# En iyi model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Model değerlendirme\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Accuracy: {accuracy:.4f}, ROC AUC: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best parameters\n",
    "\n",
    "# En iyi modelin hyperparameter'ları\n",
    "best_params = {'subsample': 0.9, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
    "\n",
    "# En iyi modelin yeniden oluşturulması\n",
    "best_model = XGBClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Model Evaluation\n",
    "evaluate_model(best_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model Success Metrics Visuals\n",
    "evaluate_model_performance(best_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13- Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi modelin yeniden oluşturulması\n",
    "best_model = XGBClassifier(**best_params, random_state=42)\n",
    "\n",
    "# k-katlı çapraz doğrulama\n",
    "k = 10  # 10 katlı çapraz doğrulama\n",
    "stratified_kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc_aucs = []\n",
    "test_roc_aucs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_resampled\n",
    "y = y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Eğitim seti üzerindeki değerlendirme\n",
    "    y_train_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(y_train, y_train_proba)\n",
    "    train_roc_aucs.append(train_roc_auc)\n",
    "    \n",
    "    # Test seti üzerindeki değerlendirme\n",
    "    y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "    test_roc_aucs.append(test_roc_auc)\n",
    "    \n",
    "    # Fold sonuçlarını yazdırma\n",
    "    print(\"Fold Performance\")\n",
    "    print(f\"Train ROC AUC: {train_roc_auc:.4f}\")\n",
    "    print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Çapraz doğrulama sonuçları\n",
    "print(\"Cross-Validation Results\")\n",
    "print(f\"Mean Train ROC AUC: {np.mean(train_roc_aucs):.4f}, Std Train ROC AUC: {np.std(train_roc_aucs):.4f}\")\n",
    "print(f\"Mean Test ROC AUC: {np.mean(test_roc_aucs):.4f}, Std Test ROC AUC: {np.std(test_roc_aucs):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
